---
title: "Our website: from Github to production"
date: 2018-01-03T22:30:27-03:00
draft: true
categories: ["WebSite"]
tags: ["hugo", "aws"]
authors: ["Felipe Zipitria"]
---

Our website is created using [hugo](https://gohugo.io), a very fast and stable static website generator, based on the files in our Git repository.

Normally I use atom or code to edit content in markdown. It's very easy to iterate locally seeing the changes to your site using `hugo serve` to watch changes in real-time. When you are ready to publish, we needed a way to grab the files from our repository, and pass them to `hugo` to generate the static pages.

This site is hosted in AWS CloudFront, that reads the HTML and CSS static files generated by hugo from a AWS S3 Bucket. So to go from the source files in markdown to the HTML + CSS files we setup a pipeline using AWS CodeBuild. In the figure below we show the complete flow used.

{{< figure src="/img/blog/github-repo-flow.png" title="Website Generation Flow Figure" width="720px" >}}

When any user pushes or commits to github (1), a webhook calls the apropiate AWS CodeBuild process for beginning the build (2). The build then clones the repo (3), and executes hugo (4) to end the build phase. Deployment is made by saving the resulting files in the S3 bucket (5), and invalidating the distribution (6). The user will see the new pages shortwhile after (7).

The hugo execution uses the [config.toml](https://raw.githubusercontent.com/project-cx/pbx-group-security/master/config.toml) file at the current directory for generating the site in the `public` directory. Synchronization to the resulting bucket is made with the aws-cli tools:

```shell
aws s3 sync --acl "public-read" --sse "AES256" public/ s3://$BUCKET_NAME --exclude 'post'
```

After sinchronization, we need to tell CloudFront that its cached data copy needs to be reloaded from our bucket.

```shell
aws cloudfront create-invalidation --distribution-id $DISTRIBUTION_ID --paths /index.html / /page/* /css/* /blog/* /contact/* /challenges/* /roles/*
```

This provides us with a perfect way of providing a site which is created using the traditional git flow.

## The Gory Details

If you want to have a simple setup like ours, you need to create two things: the Github repository that will hold the source files, and the AWS infrastructure for serving your static pages.

### Github Repository

If you don't have a repository, you can clone a [hugo starter kit](https://gohugo.io/tools/starter-kits/) to begin with. If you already have your repository created, skip this step. In Github then you will need

### AWS Setup

For the AWS part you will need:
- an S3 bucket
- a CloudFront distribution that serves content from this bucket
- a domain in Route 53 that points to your cloudfront distribution

There is a helper tool from CloudFlare called [stout](http://stout.is/) that does exactly that: it creates the S3 bucket, the CloudFront distribution, and configures the Route 53, all in a single step. It is a unique Go binary, allowing to easy inclusion in your pipeline.

So the first step is to export some environment variables for the aws tools:
```shell
export AWS_ACCESS_KEY_ID=aaaa
export AWS_SECRET_ACCESS_KEY=bbb
export AWS_DEFAULT_REGION=us-east-1 #(insert your desired bucket region)
```

Then execute the command to all that in one step:
```shell
stout create --bucket my.website.com
```

#### Manual permissions setup

The policy you will need to set in IAM to save files in your S3 bucket, if you choose to do this manually, are:
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": [
                "s3:PutObject",
                "s3:PutObjectAcl",
                "s3:GetObject",
                "s3:DeleteObject"
            ],
            "Resource": "arn:aws:s3:::my.website.com/*",
            "Effect": "Allow"
        },
        {
            "Action": [
                "s3:ListBucket"
            ],
            "Resource": "arn:aws:s3:::my.website.com",
            "Effect": "Allow"
        }
    ]
}
```
Don't forget to add the `s3:PutObjectAcl`, or you will not have your permissions correctly set or have errors when deploying.

To create invalidations on CloudFront, use this policy:
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "InvalidateDistribution",
            "Effect": "Allow",
            "Action": [
                "cloudfront:GetDistribution",
                "cloudfront:GetCloudFrontOriginAccessIdentityConfig",
                "cloudfront:ListInvalidations",
                "cloudfront:ListDistributions",
                "cloudfront:GetInvalidation",
                "cloudfront:GetCloudFrontOriginAccessIdentity",
                "cloudfront:GetDistributionConfig",
                "cloudfront:CreateInvalidation"
            ],
            "Resource": "*"
        }
    ]
}
```
Finally, you will need a new User with this policies applied. 

### Using CodeBuild

Now we need to connect the dots: after each succesful merge or commit, we need to fire the hugo build and push the resulting HTML to our S3 bucket.

This glue is made using AWS CodeBuild. CodeBuild, when run, will read a file called [buildspec.yml](https://raw.githubusercontent.com/project-cx/pbx-group-security/master/buildspec.yml) with commands to be executed for building.

By default, the build form AWS is made in an Ubuntu 14.04 box. We download first the hugo binary, and then execute it to generate the website.
```yaml
  install:
    commands:
      - git clone https://github.com/photobox/pbx-group-security.git
      - curl -Ls https://github.com/gohugoio/hugo/releases/download/v0.31.1/hugo_0.31.1_Linux-64bit.tar.gz -o ./hugo.tar.gz
      - tar xf ./hugo.tar.gz
      - mv hugo /usr/bin/
      - hugo version
  build:
    commands:
      - cd pbx-group-security && hugo
```

After the (succesful) build, we push to our S3 bucket and invalidate the CloudFront cache:
```yaml
post_build:
    commands:
      - cd pbx-group-security && aws s3 sync --acl "public-read" --sse "AES256" public/ s3://pbx-group-security.com-cdn --exclude 'post'
      - aws configure set preview.cloudfront true
      - aws cloudfront create-invalidation --distribution-id E3K53GHHL4D0LE --paths /index.html / /page/* /css/* /blog/*
```

The invalidation will be fired in this step, but depending on the size of your fileset, it could take some minutes to propagate.